import streamlit as st
from pdfminer.high_level import extract_text
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
import tempfile
import os
import httpx
import tiktoken
tiktoken_cache_dir = "./token"
os.environ["TIKTOKEN_CACHE_DIR"] = tiktoken_cache_dir
client = httpx.Client(verify=False)
# LLM and Embedding setup
llm = ChatOpenAI(
base_url="https://genailab.tcs.in",
model="azure_ai/genailab-maas-DeepSeek-V3-0324",
api_key="sk-h4SzToxOqOneSAXq191PXA",
http_client=client
)
embedding_model = OpenAIEmbeddings(
base_url="https://genailab.tcs.in",
model="azure/genailab-maas-text-embedding-3-large",
api_key="sk-h4SzToxOqOneSAXq191PXA",
http_client=client
)
st.set_page_config(page_title="RAG PDF Summarizer")
st.title(" RAG-powered PDF Summarizer")
upload_file = st.file_uploader("Upload a PDF", type="pdf")
During the last dry run our teams had quite a lot of learnings and this time sharing this 
code as well. But there should be no change to the way we are programming etc.
if upload_file:
with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_file:
temp_file.write(upload_file.read())
temp_file_path = temp_file.name
# Step 1: Extract text
raw_text = extract_text(temp_file_path)
# Step 2: Chunking
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
chunks = text_splitter.split_text(raw_text)
# Step 3: Embed and store in Chroma
with st.spinner("Indexing document..."):
vectordb = Chroma.from_texts(chunks, embedding_model, 
persist_directory="./chroma_index")
vectordb.persist()
# Step 4: RAG QA Chain
#retriever = vectordb.as_retriever(search_type="similarity", search_kwargs={"k": 5})
retriever = vectordb.as_retriever()
rag_chain = RetrievalQA.from_chain_type(
llm=llm,
retriever=retriever,
return_source_documents=True
)
# Step 5: Ask summarization prompt
summary_prompt = "Please summarize this document based on the key topics:"
with st.spinner("Running RAG summarization..."):
# result = rag_chain.run(summary_prompt)
result = rag_chain.invoke(summary_prompt)
st.subheader(" Summary")
st.write(result)
